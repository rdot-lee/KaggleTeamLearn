{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "處理非數值欄位有三種方法\n",
    "1.直接砍掉\n",
    "2.幫他們編號，並保有排序，例如國外成績A,B,C 轉換成分數90,80,70\n",
    "3.轉換0和1組成的向量,ex:藍藍黑紅\n",
    "藍:(1,1,0,0)\n",
    "黑:(0,0,1,0)\n",
    "紅:(0,0,0,1)\n",
    "\n",
    "\n",
    "補充:\n",
    "2.Ordinal encoding 是將類別變量轉化為有序數值的策略。它將每個類別分別映射到一個整數上，並保留類別之間的大小關係。\n",
    "3.One-hot encoding 是一種將類別變量轉化為一個由 0 和 1 組成的向量的策略。它將每個類別分別映射到一個新的二元特徵上。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "補充一下前面講到處理缺失值有3種方法, 其中simpleimputer有一個參數是simpleimputer(stragety='most_frequent'),\n",
    "這可以搭配onehotencoder一起使用, 簡單來說就是處理非數值欄位的缺失值, 具體做法會在04.ipynb講到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/Rich/Desktop/Kaggle/KaggleTeamLearn/Rich/Internediate ML/melb_data.csv')\n",
    "\n",
    "\n",
    "y = data.Price\n",
    "X = data.drop(['Price'], axis=1)\n",
    "\n",
    "\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
    "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "\n",
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984    144.9867        13240.0  \n",
       "6524        2.0     193.0  -37.85800    144.9005         6380.0  \n",
       "8413        1.0     555.0  -37.79880    144.8220         3755.0  \n",
       "2919        1.0     265.0  -37.70830    144.9158         8870.0  \n",
       "6043        1.0     673.0  -37.76230    144.8272         4217.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Rooms.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.Distance.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s = (X_train.dtypes == 'object')\n",
    "#這行可以理解成是把X_train的每一個column的type都跟object比較，如果是object的話就會是True，\n",
    "#如果不是的話就會是False，並且會印出True的column name\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "175703.48185157913\n"
     ]
    }
   ],
   "source": [
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "165936.40548390493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
    "\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type', 'Method', 'Regionname']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rich/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "#handle_unknown = 'ignore' 這個參數是說如果有新的類別出現的話，就不要報錯，而是直接忽略\n",
    "#sparse = False 這個參數是說不要用稀疏 matrix，而是用一般的matrix\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#步驟是先設定好，然後用fit_transform去fit X_train，然後再用transform去fit X_valid\n",
    "#接著設定index，最後再把兩個dataframe合併起來(因為我們在處理的是非數值col所以我們前面把他切出來)\n",
    "\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "#這個方法會把原本的column name拿掉，所以要重新加回來\n",
    "\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = pd.read_csv('/Users/Rich/Desktop/Kaggle/KaggleTeamLearn/Rich/Internediate ML/home-data-for-ml-course/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('/Users/Rich/Desktop/Kaggle/KaggleTeamLearn/Rich/Internediate ML/home-data-for-ml-course/test.csv', index_col='Id')\n",
    "\n",
    "\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                         \n",
       "619           20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871           20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93            30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818           20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303           20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "...          ...      ...      ...    ...      ...         ...       ...   \n",
       "764           60       RL     9430   Pave      Reg         Lvl    AllPub   \n",
       "836           20       RL     9600   Pave      Reg         Lvl    AllPub   \n",
       "1217          90       RM     8930   Pave      Reg         Lvl    AllPub   \n",
       "560          120       RL     3196   Pave      Reg         Lvl    AllPub   \n",
       "685           60       RL    16770   Pave      IR2         Lvl    AllPub   \n",
       "\n",
       "     LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch  \\\n",
       "Id                                     ...                             \n",
       "619     Inside       Gtl      NridgHt  ...         108             0   \n",
       "871     Inside       Gtl        NAmes  ...           0             0   \n",
       "93      Inside       Gtl      Crawfor  ...           0            44   \n",
       "818    CulDSac       Gtl      Mitchel  ...          59             0   \n",
       "303     Corner       Gtl      CollgCr  ...          81             0   \n",
       "...        ...       ...          ...  ...         ...           ...   \n",
       "764     Inside       Gtl      NoRidge  ...         128             0   \n",
       "836     Inside       Gtl       Sawyer  ...           0             0   \n",
       "1217    Inside       Gtl       Sawyer  ...           0             0   \n",
       "560     Inside       Gtl      Blmngtn  ...          20             0   \n",
       "685    CulDSac       Gtl      NoRidge  ...          81             0   \n",
       "\n",
       "     3SsnPorch ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType  \\\n",
       "Id                                                                       \n",
       "619          0         260         0        0       7    2007      New   \n",
       "871          0           0         0        0       8    2009       WD   \n",
       "93           0           0         0        0       8    2009       WD   \n",
       "818          0           0         0        0       7    2008       WD   \n",
       "303          0           0         0        0       1    2006       WD   \n",
       "...        ...         ...       ...      ...     ...     ...      ...   \n",
       "764          0         180         0        0       7    2009       WD   \n",
       "836          0           0         0        0       2    2010       WD   \n",
       "1217         0           0         0        0       4    2010       WD   \n",
       "560          0           0         0        0      10    2006       WD   \n",
       "685          0           0         0        0       6    2010       WD   \n",
       "\n",
       "     SaleCondition  \n",
       "Id                  \n",
       "619        Partial  \n",
       "871         Normal  \n",
       "93          Normal  \n",
       "818         Normal  \n",
       "303         Normal  \n",
       "...            ...  \n",
       "764         Normal  \n",
       "836         Normal  \n",
       "1217        Normal  \n",
       "560         Normal  \n",
       "685         Normal  \n",
       "\n",
       "[1168 rows x 60 columns]>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用刪除法把非數值column刪除\n",
    "#Hint:使用select_dtypes()\n",
    "#drop_X_train = X_\n",
    "#drop_X_train = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "#label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "#label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# 使用編碼法把非數值column填滿\n",
    "#hint:使用OrdinalEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use as many lines of code as you need!\n",
    "onehot_encoder = OneHotEncoder()\n",
    "#OH_X_train = onehot_encoder.fit_transform(X_train)\n",
    "#使用onehot_encoder填補缺失值\n",
    "#OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "#OH_X_valid = OH_encoder.fit_transform(X_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
